# Distribui√ß√£o de Probabilidades da fun√ß√£o armadilha de ordem $k$

Nesta nota, deduzimos a probabilidade de $f_k(x)=r$ sendo $f_k:\mathbb{Z}_2^n\rightarrow\mathbb{Z}$ definida por:

$$
f_k(x) := \sum_{i=1}^{n/k} \text{trap}_k\left( \sum_{j=1}^k x_{(i-1)k + j} \right)
$$

onde,


$$
\text{trap}_k(u) =
\begin{cases}
k, & \text{se } u = k, \\
k - 1 - u, & \text{se } 0 \le u < k.
\end{cases}
$$

Isto √©, queremos deduzir a probabilidade:

$$
P(f_k(x) = r), \quad \text{com } x \in \mathbb{Z}_2^n,\ r \in \lbrace0,1,\dots,mk\rbrace, \text{ onde } m = n/k.
$$

---

## Defini√ß√µes e estrutura

### 1. Vari√°vel de entrada
$$
x = (x_1, x_2, \ldots, x_n) \in \mathbb{Z}_2^n
$$

√â um vetor aleat√≥rio uniformemente distribu√≠do ‚Äî todas as $2^n$ combina√ß√µes t√™m mesma probabilidade.


### 2. Distribui√ß√£o da Fun√ß√£o OneMax

Seja $\Omega:\mathbb{Z}_2^n\rightarrow\mathbb{Z}$ definida por:

$$
\Omega(x):=\sum_{i=1}^n x_i
$$

A probabilidade $\Omega(x)=r$ com $r \in \lbrace0,1,\dots,n\rbrace$ √© dada por:

1. O n√∫mero de vetores que satisfazem $\Omega(x)=r$ √© $\binom{n}{r}$. Pois esta √© a contagem de combina√ß√µes do vetor $x$ com exatamente $r$ componentes iguais a $1$.

2. Cada vetor tem probabilidade $\frac{1}{2^n}$. Supondo sele√ß√£o aleat√≥ria do $x$, isto √©, $x \sim\mathcal{U}(0,n)$.

Logo,

$$
P\big(\Omega(x)=r\big)=\binom{n}{r}\frac{1}{2^n}=\frac{n!}{2^n r!(n-r)!}.
$$

### 3. Divis√£o em blocos


Definimos $m$ o n√∫mero de blocos de tamnho $k$:

$$
m := \frac{n}{k}.
$$

Para cada bloco $i = 1, \dots, m$, temos:

$$
s_i := \sum_{j=1}^{k} x_{(i-1)k + j},\quad \text{o n√∫mero de uns no bloco $i$}
$$

Assim cada $s_i \in \lbrace0,1,\dots,k\rbrace$, √© resultado de uma OneMax e segue distribui√ß√£o binomial $\mathcal{B}(k, 1/2)$.

---


## Objetivo

Calcular:

$$
P\left( \sum_{i=1}^m \text{trap}_k(s_i) = r \right)
$$

com $s_i \sim \mathcal{B}(k, 1/2)$, independentes.


### 1 ‚Äì Distribui√ß√£o de $\text{trap}_k(s_i)$

Seja $T_i := \text{trap}_k(s_i)$

Vamos calcular a distribui√ß√£o de $T_i$.

Como $s_i \sim B(k, 1/2)$, temos:

$$
P(s_i = u) = \binom{k}{u} \cdot \frac{1}{2^k}, \quad u = 0, 1, \dots, k
$$

E usando a defini√ß√£o da trap:

- Se $u = k$, ent√£o $\text{trap}_k(u) = k$, com probabilidade $P(s_i = k)$
- Se $u < k$, ent√£o $\text{trap}_k(u) = k - 1 - u$, com probabilidade $P(s_i = u)$

Logo, podemos definir a distribui√ß√£o discreta de $T_i$:

$$
P(T_i = r) = 
\begin{cases}
\frac{1}{2^k}\binom{k}{k} = \frac{1}{2^k}, & \text{se } r = k, \\
\frac{\binom{k}{u}}{2^k}, & \text{se } r = k - 1 - u,\ u < k.
\end{cases}
$$

Todo $r \in \lbrace0, 1, \dots, k-1\rbrace$ √© mapeado por $u = k - 1 - r$, ent√£o:

$$
P(T_i = r) =
\begin{cases}
\frac{1}{2^k}, & \text{se } r = k, \\
\frac{\binom{k}{k - 1 - r}}{2^k}, & \text{se } 0 \le r < k.
\end{cases}
$$



## 2 ‚Äì Soma de $m$ vari√°veis independentes $T_1 + T_2 + \cdots + T_m$

Como os $T_i$ s√£o independentes e id√™nticos (i.i.d.), a soma:

$$
f_k(x) = \sum_{i=1}^m T_i
$$

√© a soma de $m$ vari√°veis i.i.d. discretas.

Logo, a distribui√ß√£o de $f_k(x)$ √© a **convolu√ß√£o** $m$-vezes da distribui√ß√£o de $T_1$:

$$
P(f_k(x) = r) = \left(P_{T_1} * P_{T_2} * \cdots * P_{T_m}\right)(r) = P_{T}^{(*m)}(r)
$$

---

## Resultado final

Seja $P_{\text{trap}_k}$ o vetor de distribui√ß√£o discreta de $\text{trap}_k(s_i)$. Ent√£o:

$$
P(f_k(x) = r) = P_{\text{trap}_k}^{(*m)}(r)
$$

Esse m√©todo nos permite calcular a distribui√ß√£o $P(f_k(x)=r)$ para qualquer $n$ e $k$ com $k \mid n$, sem gerar todos os $2^n$ vetores.

---

## Revis√£o sobre Convolu√ß√£o

Excelente! A **convolu√ß√£o** √© um conceito fundamental em probabilidade, especialmente quando estamos lidando com **somas de vari√°veis aleat√≥rias independentes**. Vamos construir a ideia passo a passo, com foco na intui√ß√£o e rigor matem√°tico üëá


### 1. Contexto geral

Suponha que temos duas vari√°veis aleat√≥rias discretas **independentes**:

- $X$ com distribui√ß√£o $P_X(x)$
- $Y$ com distribui√ß√£o $P_Y(y)$

Queremos saber a distribui√ß√£o da soma $Z = X + Y$.


### 2. Defini√ß√£o da convolu√ß√£o

A **distribui√ß√£o de $Z = X + Y$** √© dada pela **convolu√ß√£o** de $P_X$ e $P_Y$:

$$
P_Z(z) = (P_X * P_Y)(z) = \sum_{x} P_X(x) \cdot P_Y(z - x)
$$

Em outras palavras:

- Para cada valor $z$, somamos todos os pares $(x, y)$ tais que $x + y = z$.
- Como $X$ e $Y$ s√£o independentes, a probabilidade conjunta √© o produto das marginais: $P(X = x, Y = z - x) = P_X(x) \cdot P_Y(z - x)$.

### 3. Intui√ß√£o

A convolu√ß√£o responde:  
> "Qual √© a probabilidade de que **a soma** de duas vari√°veis independentes assuma um valor $z$?"

Ela **varre todos os jeitos poss√≠veis** de decompor $z$ como $x + y$, e soma as probabilidades correspondentes.


### 4. Exemplo

Seja $X, Y \in \{0,1\}$, com:

- $P_X(0) = P_X(1) = 0.5$
- $P_Y(0) = P_Y(1) = 0.5$

Ent√£o $Z = X + Y \in \{0,1,2\}$

$$
\begin{align*}
P_Z(0) &= P_X(0) \cdot P_Y(0) = 0.25 \\
P_Z(1) &= P_X(0) \cdot P_Y(1) + P_X(1) \cdot P_Y(0) = 0.25 + 0.25 = 0.5 \\
P_Z(2) &= P_X(1) \cdot P_Y(1) = 0.25
\end{align*}
$$

